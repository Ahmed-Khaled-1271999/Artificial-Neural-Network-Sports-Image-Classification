{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From /home/ahmed/anaconda3/envs/Neural/lib/python3.6/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"]}],"source":["import os\n","\n","from random import shuffle\n","\n","import pandas as pd\n","\n","import cv2\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm\n","\n","import tensorflow as tf\n","import tflearn\n","\n","from tflearn.layers.conv import conv_2d, max_pool_2d\n","from tflearn.layers.core import input_data, dropout, fully_connected\n","from tflearn.layers.estimator import regression\n","from tflearn.data_preprocessing import ImagePreprocessing\n","from tflearn.data_augmentation import ImageAugmentation"]},{"cell_type":"markdown","metadata":{},"source":["# Global Independent Variables (Hyper-Parameters) - Identify The Model"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["# Labels Vectors\n","categories = {\n","'Basketball':  np.array([1, 0, 0, 0, 0, 0]),\n","'Football':    np.array([0, 1, 0, 0, 0, 0]),\n","'Rowing':      np.array([0, 0, 1, 0, 0, 0]),\n","'Swimming':    np.array([0, 0, 0, 1, 0, 0]),\n","'Tennis':      np.array([0, 0, 0, 0, 1, 0]),\n","'Yoga':        np.array([0, 0, 0, 0, 0, 1])\n","}\n"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["TRAIN_DIR = './Input/Train/'\n","TEST_DIR = './Input/NTest/'\n","# TEST_DIR = './Input/Test/'\n","IMG_SIZE = 50\n","LR = 0.001\n","MODEL_NAME = 'sports-image-classification-cnn'"]},{"cell_type":"markdown","metadata":{},"source":["# Helpers"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["def create_label(image_name):\n","    \"\"\" Create an one-hot encoded vector from image name \"\"\"\n","    word_label = image_name.split('_')[0]\n","    return categories[word_label]"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["def create_train_data():\n","    \"\"\"To bring Train Images from the State of Raw Files into Structured Numpy Array with its Label attatched with it.\n","    Returns:\n","        np.ndarray: Training Images [np.array(img), its Label]\n","    \"\"\"\n","    training_data = []\n","    \n","    for img in tqdm(os.listdir(TRAIN_DIR)):\n","        path = os.path.join(TRAIN_DIR, img)\n","    \n","        img_data = cv2.imread(path, 1)                                   # 0: Read Img as Grayscale\n","        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE)) \n","        \n","        training_data.append([np.array(img_data), create_label(img)])\n","        \n","    shuffle(training_data)\n","    np.save('train_data.npy', training_data)\n","    \n","    return training_data"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["def create_test_data():\n","    testing_data=[]\n","    \n","    for img in tqdm(os.listdir(TEST_DIR)):\n","        path = os.path.join(TEST_DIR, img)\n","        \n","        img_data = cv2.imread(path, 1)\n","        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n","        \n","        testing_data.append([img, np.array(img_data)])\n","        \n","    np.save('test_data.npy', np.array(testing_data))\n","    \n","    return np.array(testing_data)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def prob_to_output(probabilities):\n","    predictions = []\n","    \n","    for probability in probabilities:\n","        max_index = np.where(probability == max(probability))[0][0]\n","        predict = np.zeros(shape=probability.shape)\n","        predict[max_index] = 1.0\n","        predictions.append(predict)\n","        \n","    return predictions"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def output_to_label(output_vectors):\n","    return [np.where(vector == 1)[0][0] for vector in output_vectors]"]},{"cell_type":"markdown","metadata":{},"source":["# Data Preparation"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# # Real-time image preprocessing\n","# img_prep = ImagePreprocessing()\n","# # \n","# img_prep.add_featurewise_zero_center()\n","# img_prep.add_featurewise_stdnorm()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# # Real-time data augmentation\n","# img_aug = ImageAugmentation()\n","# #\n","# img_aug.add_random_flip_leftright()\n","# img_aug.add_random_rotation(max_angle=25.)"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["# Do not do it Twice!\n","if (os.path.exists('train_data.npy')):\n","    train_data =np.load('train_data.npy',allow_pickle=True)\n","else: \n","    train_data = create_train_data()"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["# Seprate Labels from Raw Image Matrices\n","X_train = np.array([i[0] for i in train_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n","Y_train = [i[1] for i in train_data]"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(6,)\n","(1681, 50, 50, 3)\n"]}],"source":["print(Y_train[0].shape)\n","print(X_train.shape)"]},{"cell_type":"markdown","metadata":{},"source":["# Model سِره فـ أضعف خلقه"]},{"cell_type":"markdown","metadata":{},"source":["## Construction"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["tf.compat.v1.reset_default_graph()"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From /home/ahmed/anaconda3/envs/Neural/lib/python3.6/site-packages/tflearn/initializations.py:110: calling UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /home/ahmed/anaconda3/envs/Neural/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:538: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n","WARNING:tensorflow:From /home/ahmed/anaconda3/envs/Neural/lib/python3.6/site-packages/tflearn/initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /home/ahmed/anaconda3/envs/Neural/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"]}],"source":["conv_input = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 3], name='input')    \n","# \n","conv1 = conv_2d(conv_input, 32, 5, activation='relu')    # 32 Feature Maps\\Filters ~ Kernel Size = 5x5\n","pool1 = max_pool_2d(conv1, 5)\n","\n","conv2 = conv_2d(pool1, 64, 5, activation='relu')\n","pool2 = max_pool_2d(conv2, 5)\n","\n","conv3 = conv_2d(pool2, 128, 5, activation='relu')\n","pool3 = max_pool_2d(conv3, 5)\n","\n","conv4 = conv_2d(pool3, 64, 5, activation='relu')\n","pool4 = max_pool_2d(conv4, 5)\n","\n","conv5 = conv_2d(pool4, 32, 5, activation='relu')\n","pool5 = max_pool_2d(conv5, 5)\n","#  \n","fully_layer = fully_connected(pool5, 1024, activation='relu')    # 1024 Neurons\n","fully_layer = dropout(fully_layer, 0.5)    # ~ dropout one-half\n","# \n","cnn_layers = fully_connected(fully_layer, 6, activation='softmax')    # 6 Categories\n","# \n","cnn_layers = regression(cnn_layers, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n","# \n","secret_in_weakest = tflearn.DNN(cnn_layers, tensorboard_dir='log', tensorboard_verbose=3)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Runtime Session"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Step: 699  | total loss: \u001b[1m\u001b[32m0.32442\u001b[0m\u001b[0m | time: 7.497s\n","| Adam | epoch: 050 | loss: 0.32442 - acc: 0.9702 -- iter: 1248/1344\n","Training Step: 700  | total loss: \u001b[1m\u001b[32m0.29351\u001b[0m\u001b[0m | time: 9.078s\n","| Adam | epoch: 050 | loss: 0.29351 - acc: 0.9731 | val_loss: 0.87212 - val_acc: 0.7953 -- iter: 1344/1344\n","--\n"]}],"source":["secret_in_weakest.fit(X_train, Y_train, n_epoch=10, shuffle=True, validation_set=0.2,\n","          show_metric=True, batch_size=96, run_id=MODEL_NAME)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Testing & Competition Submissions"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 93/93 [00:00<00:00, 214.08it/s]\n","/home/ahmed/anaconda3/envs/Neural/lib/python3.6/site-packages/ipykernel_launcher.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  if sys.path[0] == '':\n","/home/ahmed/anaconda3/envs/Neural/lib/python3.6/site-packages/ipykernel_launcher.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  \n"]}],"source":["# Do not do it Twice!\n","if (os.path.exists('test_data.npy')):\n","    test_data =np.load('test_data.npy',allow_pickle=True)\n","else: \n","    test_data = create_test_data()"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["X_test = np.array([i[1] for i in test_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n","image_names = [i[0] for i in test_data]"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["(93, 50, 50, 3)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["X_test.shape"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["<tflearn.models.dnn.DNN at 0x7f59439f7d30>"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["secret_in_weakest"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[],"source":["predictions = secret_in_weakest.predict(X_test)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["results = prob_to_output(predictions)"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["[5, 4, 3, 4, 4, 1, 5, 4, 4, 3]"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["labels = output_to_label(results)\n","labels[:10]"]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":true},"outputs":[],"source":["submission=pd.DataFrame()\n","submission['image_name'] = image_names\n","submission['label'] = labels\n","submission.to_csv(\"submission_prctical.csv\",index=False)"]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>75.jpg</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>37.jpg</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  image_name  label\n","0     75.jpg      5\n","1     37.jpg      4"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["pd.read_csv('./submission_prctical.csv').head(2)"]},{"cell_type":"markdown","metadata":{},"source":["# Tensorboard and Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# End of Model"]},{"cell_type":"markdown","metadata":{},"source":["# Packages Installations"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[],"source":["# ! pip install tflearn"]},{"cell_type":"code","execution_count":27,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["'\\nconda create -n NeuralHandsOn python=3.6\\npip install tensorflow==2.4\\npip install opencv-python\\npip install matplotlib\\npip install scipy\\nconda install tflearn\\nconda install -c conda-forge tqdm\\nconda install -c anaconda qt\\n'"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["# REQUIREMENTS MAY BE NEEDED\n","\"\"\"\n","conda create -n NeuralHandsOn python=3.6\n","pip install tensorflow==2.4\n","pip install opencv-python\n","pip install matplotlib\n","pip install scipy\n","conda install tflearn\n","conda install -c conda-forge tqdm\n","conda install -c anaconda qt\n","\"\"\""]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["# prevent scientific notation\n","np.set_printoptions(suppress=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Garbage Codes"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["# # Model Training ~ Do not train same Thing Twice\n","# if (os.path.exists('secret_in_weakest.tfl.meta')):\n","#     secret_in_weakest.load('./secret_in_weakest.tfl')\n","# else:\n","#     secret_in_weakest.fit(X_train, Y_train, n_epoch=50, shuffle=True, validation_set=0.2,\n","#           show_metric=True, batch_size=96, run_id=MODEL_NAME)\n","#     secret_in_weakest.save('secret_in_weakest.tfl')"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["# conv_input = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 3], name='input',\n","#                         data_preprocessing=img_prep,\n","#                         data_augmentation=img_aug"]}],"metadata":{"kernelspec":{"display_name":"Neural","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"vscode":{"interpreter":{"hash":"690efd406daf46e81645850d55b6b17c1d3753bcdff5c6c11e6c9ebfe1569c71"}}},"nbformat":4,"nbformat_minor":4}
